{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Perceptron\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "from itertools import cycle\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/agaricus-lepiota.data')\n",
    "data.replace(\"?\", pd.NA, inplace=True)\n",
    "data.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing data by removing all rows that have missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the data to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lben = LabelEncoder()\n",
    "\n",
    "for column in data.columns:\n",
    "    data[column] = lben.fit_transform(data[column])\n",
    "    \n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into two parts: a training part and a testing part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.drop(columns='p')\n",
    "target = data['p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=1/3.0, random_state=42)\n",
    "print(f\"Length of X train: {len(X_train)}\")\n",
    "print(f\"Length of y train: {len(y_train)}\")\n",
    "print(f\"Length of X test: {len(X_test)}\")\n",
    "print(f\"Length of y test: {len(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data with Support Vector Machine model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron_model = Perceptron(shuffle=True, random_state=0)\n",
    "perceptron_model.fit(X_train, y_train)\n",
    "\n",
    "y_predict = perceptron_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Weight: {perceptron_model.coef_}\")\n",
    "print(f\"Intercept: {perceptron_model.intercept_}\")\n",
    "print(f\"Iteration: {perceptron_model.n_iter_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(perceptron_model, open(\"Perceptron_Model.sav\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the accuracy, recallm precision and F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_values, y_test_counts = np.unique(y_test, return_counts=True)\n",
    "plt.bar([str(value) for value in y_test_values], y_test_counts, width=0.4)\n",
    "plt.xlabel(\"Type of label\")\n",
    "plt.ylabel(\"Number label of each type\")\n",
    "plt.title(\"Number label of each type of Y Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_values, y_pred_counts = np.unique(y_predict, return_counts=True)\n",
    "plt.bar([str(value) for value in y_pred_values], y_pred_counts, width=0.4)\n",
    "plt.xlabel(\"Type of label\")\n",
    "plt.ylabel(\"Number label of each type\")\n",
    "plt.title(\"Number label of each type of Y Predict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = [\"0\", \"1\"]\n",
    "X_axis = np.arange(len(groups)) \n",
    "\n",
    "    \n",
    "plt.figure(figsize=(9,8))\n",
    "\n",
    "\n",
    "\n",
    "for bar in plt.bar(X_axis - 0.2, y_test_counts, width=0.35, label=\"Y test\"):\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval, yval, ha='center', va='bottom')\n",
    "    \n",
    "for bar in plt.bar(X_axis + 0.2, y_pred_counts, width=0.35, label=\"Y Predict\"):\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval, yval, ha='center', va='bottom')\n",
    "\n",
    "\n",
    "plt.xticks(X_axis, groups) \n",
    "plt.xlabel(\"Groups\")\n",
    "plt.ylabel(\"Number label of each type in each Y\")\n",
    "plt.title(\"Compare Y test and Y predict\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_predict)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_predict, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_predict, y_test).ravel()\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1 = 2*(precision*recall)/(precision+recall)\n",
    "\n",
    "print(f\"Precisioin = {precision}\")\n",
    "print(f\"Recall = {recall}\")\n",
    "print(f\"F1 = {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform 22-D data to 2-D data and display it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_model = PCA(n_components = 2, whiten = True).fit(features)\n",
    "features_pca = pca_model.transform(features)\n",
    "\n",
    "pd.DataFrame(data = features_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = cycle(\"rgb\")\n",
    "target_names = [0, 1]\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "target_list = target.to_numpy().flatten()\n",
    "for t_name, c in zip(target_names, colors):\n",
    "    plt.scatter(features_pca[target_list == t_name, 0], features_pca[target_list == t_name, 1], c=c, label=t_name)\n",
    "\n",
    "plt.legend()    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the reduced data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(features_pca[:, 0], features_pca[:, 1], c=target, cmap='viridis', edgecolor='k', s=50)\n",
    "\n",
    "# Create a mesh grid for the decision boundary\n",
    "x_min, x_max = features_pca[:, 0].min() - 1, features_pca[:, 0].max() + 1\n",
    "y_min, y_max = features_pca[:, 1].min() - 1, features_pca[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01), np.arange(y_min, y_max, 0.01))\n",
    "\n",
    "# Predict on the mesh grid\n",
    "Z = perceptron.predict(pca_model.inverse_transform(np.c_[xx.ravel(), yy.ravel()]))\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Plot decision boundary\n",
    "plt.contourf(xx, yy, Z, alpha=0.2, cmap='viridis')\n",
    "plt.title(\"Perceptron Model Decision Boundary with PCA Reduction\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.colorbar(label='Class Label')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
